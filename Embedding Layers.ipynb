{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layers\n",
    "- Embedding layer used to convert one hot indices vectors(sentences) to n dimensions output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer,one_hot,text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences,skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['My name is Prakash', 'I have a dog', 'I have a cat with three legs']\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_sentences = [one_hot(words, vocab_size) for words in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6967, 7645, 7813, 3163],\n",
       " [7781, 1502, 1204, 4950],\n",
       " [7781, 1502, 1204, 9793, 5713, 805, 4122]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the words of sentences are changed to their indices according to vocabulary\n",
    "one_hot_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets pad all of them with same length\n",
    "max_length = 8\n",
    "padded_one_hot_sentences = pad_sequences(one_hot_sentences, max_length,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 6967, 7645, 7813, 3163],\n",
       "       [   0,    0,    0,    0, 7781, 1502, 1204, 4950],\n",
       "       [   0, 7781, 1502, 1204, 9793, 5713,  805, 4122]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_one_hot_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim=10 #Features\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=out_dim, input_length=max_length)\n",
    "])\n",
    "model.compile(\"adam\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 10)             100000    \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 6967, 7645, 7813, 3163],\n",
       "       [   0,    0,    0,    0, 7781, 1502, 1204, 4950],\n",
       "       [   0, 7781, 1502, 1204, 9793, 5713,  805, 4122]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_one_hot_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [ 0.0023398 , -0.00601881,  0.01444662, -0.04768455,\n",
       "          0.01281433, -0.03632858,  0.02604935,  0.00473189,\n",
       "         -0.02137638,  0.02137518],\n",
       "        [-0.00649123, -0.02824244,  0.01313602, -0.01033213,\n",
       "         -0.04984204,  0.03601568,  0.02464323,  0.03065279,\n",
       "          0.03606087,  0.02137338],\n",
       "        [ 0.00977827,  0.00454103,  0.03578228, -0.0451211 ,\n",
       "         -0.04464176, -0.03648539, -0.01050369,  0.00991673,\n",
       "          0.00386127,  0.04488363],\n",
       "        [ 0.02844229, -0.03984653,  0.02329898,  0.01293911,\n",
       "          0.00316383, -0.02236414,  0.04363802,  0.02610723,\n",
       "         -0.03694508,  0.03119976]],\n",
       "\n",
       "       [[-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [ 0.00964545, -0.01208131,  0.01121985, -0.03253267,\n",
       "         -0.00274531,  0.03394211, -0.016054  ,  0.0092149 ,\n",
       "          0.02867771, -0.00289597],\n",
       "        [-0.00260255, -0.0121608 , -0.02634807, -0.04150097,\n",
       "          0.03330169, -0.03979355,  0.00462334,  0.00181513,\n",
       "          0.04432197, -0.04854664],\n",
       "        [-0.03243674,  0.02778665, -0.04384813, -0.02436787,\n",
       "         -0.04175773, -0.04345683, -0.03891646,  0.0269607 ,\n",
       "          0.01994199, -0.04599009],\n",
       "        [ 0.04045855, -0.04844687, -0.00530312, -0.00134277,\n",
       "          0.03270794, -0.00217398,  0.00129882,  0.04989148,\n",
       "         -0.03412082,  0.01521022]],\n",
       "\n",
       "       [[-0.04975795, -0.00176424, -0.03522616,  0.00721263,\n",
       "         -0.0445093 ,  0.03277076,  0.02105275, -0.00984788,\n",
       "         -0.01640121, -0.01726111],\n",
       "        [ 0.00964545, -0.01208131,  0.01121985, -0.03253267,\n",
       "         -0.00274531,  0.03394211, -0.016054  ,  0.0092149 ,\n",
       "          0.02867771, -0.00289597],\n",
       "        [-0.00260255, -0.0121608 , -0.02634807, -0.04150097,\n",
       "          0.03330169, -0.03979355,  0.00462334,  0.00181513,\n",
       "          0.04432197, -0.04854664],\n",
       "        [-0.03243674,  0.02778665, -0.04384813, -0.02436787,\n",
       "         -0.04175773, -0.04345683, -0.03891646,  0.0269607 ,\n",
       "          0.01994199, -0.04599009],\n",
       "        [-0.00029331, -0.01638401,  0.00671395, -0.0173156 ,\n",
       "         -0.0293623 , -0.04020386,  0.03474417, -0.00818742,\n",
       "         -0.01023268,  0.04665947],\n",
       "        [-0.04662219, -0.03286245,  0.01021315, -0.04134964,\n",
       "         -0.00737674,  0.01304894,  0.03879939,  0.00399996,\n",
       "         -0.04762042, -0.03436585],\n",
       "        [-0.01095706,  0.02884411,  0.0005669 ,  0.04804699,\n",
       "         -0.01977611,  0.00996552,  0.04339467,  0.02737469,\n",
       "          0.00430844, -0.04344597],\n",
       "        [-0.0337391 ,  0.00234803,  0.01493526, -0.00965823,\n",
       "         -0.04165009,  0.04620728,  0.0475751 , -0.03405517,\n",
       "         -0.00486884,  0.0101693 ]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_one_hot_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04975795, -0.00176424, -0.03522616,  0.00721263, -0.0445093 ,\n",
       "         0.03277076,  0.02105275, -0.00984788, -0.01640121, -0.01726111],\n",
       "       [-0.04975795, -0.00176424, -0.03522616,  0.00721263, -0.0445093 ,\n",
       "         0.03277076,  0.02105275, -0.00984788, -0.01640121, -0.01726111],\n",
       "       [-0.04975795, -0.00176424, -0.03522616,  0.00721263, -0.0445093 ,\n",
       "         0.03277076,  0.02105275, -0.00984788, -0.01640121, -0.01726111],\n",
       "       [-0.04975795, -0.00176424, -0.03522616,  0.00721263, -0.0445093 ,\n",
       "         0.03277076,  0.02105275, -0.00984788, -0.01640121, -0.01726111],\n",
       "       [ 0.0023398 , -0.00601881,  0.01444662, -0.04768455,  0.01281433,\n",
       "        -0.03632858,  0.02604935,  0.00473189, -0.02137638,  0.02137518],\n",
       "       [-0.00649123, -0.02824244,  0.01313602, -0.01033213, -0.04984204,\n",
       "         0.03601568,  0.02464323,  0.03065279,  0.03606087,  0.02137338],\n",
       "       [ 0.00977827,  0.00454103,  0.03578228, -0.0451211 , -0.04464176,\n",
       "        -0.03648539, -0.01050369,  0.00991673,  0.00386127,  0.04488363],\n",
       "       [ 0.02844229, -0.03984653,  0.02329898,  0.01293911,  0.00316383,\n",
       "        -0.02236414,  0.04363802,  0.02610723, -0.03694508,  0.03119976]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_one_hot_sentences)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here Input indices of sentences are converted to 10 dimensional outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "- Convert sentences to one hot indices\n",
    "- pad the one hot indices\n",
    "- Use Embedding layer to convert the padded one hot indices to n(10 in above) dimensional feature representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
